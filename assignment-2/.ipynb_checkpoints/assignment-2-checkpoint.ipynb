{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fun as f\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "np.random.seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/user/Desktop/MSM/09-Deep Learning - KTH/assignments/assignment-2/Datasets/cifar-10-batches-py'\n",
    "result_pics = '/Users/user/Desktop/MSM/09-Deep Learning - KTH/assignments/assignment-1/Result_Pics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data:\n",
    "trainning_data = f.LoadBatch(os.path.join(path,'data_batch_1'))\n",
    "validation_data = f.LoadBatch(os.path.join(path,'data_batch_2'))\n",
    "test_data = f.LoadBatch(os.path.join(path,'test_batch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize weights and bias:\n",
    "W_1, b_1, W_2, b_2 = f.init_two_layers_w_b_param(trainning_data.data, trainning_data.labels, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute gradients analitically:\n",
    "grad_b_1, grad_b_2, grad_W_1, grad_W_2 = f.ComputeGradsAnalt(\n",
    "    trainning_data.data[:, 0:20], trainning_data.labels[:,0:20], b_1, b_2, W_1, W_2, lambda_=0)\n",
    "#Compute gradients numerically:\n",
    "#1.\n",
    "grad_b_1_n, grad_b_2_n, grad_W_1_n, grad_W_2_n = f.ComputeGradsNum(\n",
    "    trainning_data.data[:, 0:20], trainning_data.labels[:,0:20], W_1, W_2, b_1, b_2, h_=1e-6, lambda_=0)\n",
    "#2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.844392605193683e-06\n",
      "0.00010112146279395916\n",
      "0.003626248845054414\n",
      "6.050587200705587e-05\n"
     ]
    }
   ],
   "source": [
    "print(f.MaxRelativeError(grad_b_1, grad_b_1_n))\n",
    "print(f.MaxRelativeError(grad_b_2, grad_b_2_n))\n",
    "print(f.MaxRelativeError(grad_W_1, grad_W_1_n))\n",
    "print(f.MaxRelativeError(grad_W_2, grad_W_2_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_b_1, grad_b_2, grad_W_1, grad_W_2 = f.ComputeGradsAnalt(\n",
    "    trainning_data.data[:, 0:20], trainning_data.labels[:,0:20], b_1, b_2, W_1, W_2, lambda_=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_b_1_n, grad_b_2_n, grad_W_1_n, grad_W_2_n = f.ComputeGradsNum(\n",
    "    trainning_data.data[:, 0:20], trainning_data.labels[:,0:20], W_1, W_2, b_1, b_2, h_=1e-6, lambda_=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_size_n = np.ones((trainning_data.data.shape[1],1))\n",
    "#S_1 = mxN matrix.\n",
    "S_1 = np.matmul(W_1, trainning_data.data) + np.matmul(b_1, ind_size_n.T)\n",
    "#H = mxN matrix.\n",
    "H = f.ReLU(S_1)\n",
    "#S_2 = kxN matrix.\n",
    "S_2 = np.matmul(W_2, H) + np.matmul(b_2, ind_size_n.T)\n",
    "#P = kxN matrix.\n",
    "P = f.SOFTMAX(S_2)\n",
    "#G = kxN matrix.\n",
    "G = -(trainning_data.labels - P)\n",
    "\n",
    "grad_W_2_L = np.matmul(G,H.T) / float(trainning_data.data.shape[1])\n",
    "grad_b_2_L = np.matmul(G, ind_size_n) / float(trainning_data.data.shape[1])\n",
    "\n",
    "#Propagate the gradient back through the second layer\n",
    "\n",
    "# G = mxN\n",
    "G = np.matmul(W_2.T, G)\n",
    "\n",
    "#Compute indicator fuction:\n",
    "indicator_f_H = np.sign(H)\n",
    "\n",
    "G= G*indicator_f_H\n",
    "G[G == -0.0] = 0.0\n",
    "\n",
    "grad_W_1_L = np.matmul(G,trainning_data.data.T) / float(trainning_data.data.shape[1])\n",
    "grad_b_1_L = np.matmul(G, ind_size_n) / float(trainning_data.data.shape[1])\n",
    "\n",
    "#Compute cost function gradients:\n",
    "grad_W_1_J = grad_W_1_L + 2*(np.multiply(lambda_, W_1))\n",
    "grad_b_1_J = grad_b_1_L\n",
    "\n",
    "grad_W_2_J = grad_W_2_L  + 2*(np.multiply(lambda_, W_2))\n",
    "grad_b_2_J = grad_b_1_L"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
